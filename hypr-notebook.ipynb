{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *HunyuanVideo-PromptRewrite* Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Core functionality\n",
    "import requests\n",
    "from typing import Optional, Dict, Union, Generator, List\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GenerationConfig:\n",
    "    \"\"\"Configuration for text generation\"\"\"\n",
    "    max_tokens: int = 512\n",
    "    temperature: float = 0.0\n",
    "    top_p: float = 1.0\n",
    "    repetition_penalty: float = 1.0\n",
    "    repetition_context_size: int = 20\n",
    "    debug: bool = False\n",
    "\n",
    "def generate(prompt: str, config: GenerationConfig, stream: bool = False):\n",
    "    \"\"\"\n",
    "    Generate text with given prompt and config.\n",
    "    Prompt can contain raw special tokens.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": config.max_tokens,\n",
    "        \"temperature\": config.temperature,\n",
    "        \"top_p\": config.top_p,\n",
    "        \"repetition_penalty\": config.repetition_penalty,\n",
    "        \"repetition_context_size\": config.repetition_context_size,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "    \n",
    "    if config.debug:\n",
    "        print(\"\\nFull prompt:\")\n",
    "        print(prompt)\n",
    "        print(\"\\nRequest:\")\n",
    "        print(json.dumps(data, indent=2))\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://127.0.0.1:8080/v1/chat/completions\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=data,\n",
    "            stream=stream\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if stream:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    line = line.decode()\n",
    "                    if line.startswith(\"data: \"):\n",
    "                        if line.strip() == \"data: [DONE]\":\n",
    "                            break\n",
    "                        data = json.loads(line[5:])\n",
    "                        if content := data[\"choices\"][0].get(\"delta\", {}).get(\"content\"):\n",
    "                            yield content\n",
    "        else:\n",
    "            result = response.json()\n",
    "            if config.debug:\n",
    "                print(\"\\nResponse:\")\n",
    "                print(json.dumps(result, indent=2))\n",
    "                \n",
    "            if 'choices' in result and result['choices']:\n",
    "                return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Helper function to run generation and handle streaming\n",
    "def run_generation(prompt: str, config: GenerationConfig, stream: bool = False):\n",
    "    \"\"\"Run generation with current settings\"\"\"\n",
    "    if stream:\n",
    "        for chunk in generate(prompt, config, stream=True):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        print()  # New line at end\n",
    "    else:\n",
    "        result = generate(prompt, config, stream=False)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Inference Run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Prompt Templates and Mode Selection\n",
    "\n",
    "# The correct prompt templates\n",
    "\n",
    "normal_template = \"\"\"<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Normal mode - Video Recaption Task:\n",
    "\n",
    "You are a large language model specialized in rewriting video descriptions. Your task is to modify the input description.\n",
    "\n",
    "0. Preserve ALL information, including style words and technical terms.\n",
    "\n",
    "1. If the input is in Chinese, translate the entire description to English. \n",
    "\n",
    "2. If the input is just one or two words describing an object or person, provide a brief, simple description focusing on basic visual characteristics. Limit the description to 1-2 short sentences.\n",
    "\n",
    "3. If the input does not include style, lighting, atmosphere, you can make reasonable associations.\n",
    "\n",
    "4. Output ALL must be in English.\n",
    "\n",
    "Given Input:\n",
    "input: \"{input_text}\"<|eos|>\"\"\"\n",
    "\n",
    "master_template = \"\"\"<|startoftext|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Master mode - Video Recaption Task:\n",
    "\n",
    "You are a large language model specialized in rewriting video descriptions. Your task is to modify the input description.\n",
    "\n",
    "0. Preserve ALL information, including style words and technical terms.\n",
    "\n",
    "1. If the input is in Chinese, translate the entire description to English. \n",
    "\n",
    "2. If the input is just one or two words describing an object or person, provide a brief, simple description focusing on basic visual characteristics. Limit the description to 1-2 short sentences.\n",
    "\n",
    "3. If the input does not include style, lighting, atmosphere, you can make reasonable associations.\n",
    "\n",
    "4. Output ALL must be in English.\n",
    "\n",
    "Given Input:\n",
    "input: \"{input_text}\"<|eos|>\"\"\"\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE_ENCODE = (\n",
    "    \"<|start_header_id|>system<|end_header_id|>\\n\\nDescribe the image by detailing the color, shape, size, texture, \"\n",
    "    \"quantity, text, spatial relationships of the objects and background:<|eos|>\"\n",
    "    \"<|start_header_id|>user<|end_header_id|>\\n\\n<|eos|>\\n\\n\"\n",
    ") \n",
    "PROMPT_TEMPLATE_ENCODE_VIDEO = (\n",
    "    \"<|start_header_id|>system<|end_header_id|>\\n\\nDescribe the video by detailing the following aspects: \"\n",
    "    \"1. The main content and theme of the video.\"\n",
    "    \"2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.\"\n",
    "    \"3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.\"\n",
    "    \"4. background environment, light, style and atmosphere.\"\n",
    "    \"5. camera angles, movements, and transitions used in the video:<|eos|>\\n\"\n",
    "    \"<|start_header_id|>user<|end_header_id|>\\n\\n<|eos|>\"\n",
    ")  \n",
    "\n",
    "# Generation configs\n",
    "normal_config = GenerationConfig(\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.0,\n",
    "    debug=True,\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "master_config = GenerationConfig(\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1,\n",
    "    debug=True,\n",
    "    max_tokens=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Using a template\n",
    "input_text = \"shrek dancing\"\n",
    "prompt = normal_template.format(input_text=input_text)\n",
    "print(\"Using normal template:\")\n",
    "run_generation(prompt, normal_config, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default template with custom system prompt\n",
    "template_config = GenerationConfig(use_default_template=True, debug=True)\n",
    "run_generation(\n",
    "    \"shrek dancing\",  # Just the user input\n",
    "    template_config,\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with streaming\n",
    "print(\"\\nTesting streaming with master mode:\")\n",
    "stream_prompt = get_rewrite_prompt(\"drone shot cityscape\", mode=\"Master\")\n",
    "run_generation(stream_prompt, master_config, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Custom raw prompt with special tokens\n",
    "custom_prompt = \"\"\"{PROMPT_TEMPLATE_ENCODE_VIDEO}\n",
    "Describe a scene: shrek dancing\n",
    "<|eot_id|>\"\"\"\n",
    "\n",
    "print(\"\\nUsing custom prompt:\")\n",
    "run_generation(custom_prompt, master_config, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using custom prompt:\n",
      "\n",
      "Full prompt:\n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Describe the video by detailing the following aspects: 1. The main content and theme of the video.2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.4. background environment, light, style and atmosphere.5. camera angles, movements, and transitions used in the video:<|eos|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|eos|>\n",
      "Master mode - Video Recaption Task:\n",
      "\n",
      "You are a large language model specialized in rewriting video descriptions. Your task is to modify the input description.\n",
      "\n",
      "0. Preserve ALL information, including style words and technical terms.\n",
      "\n",
      "1. If the input is in Chinese, translate the entire description to English. \n",
      "\n",
      "2. If the input is just one or two words describing an object or person, provide a brief, simple description focusing on basic visual characteristics. Limit the description to 1-2 short sentences.\n",
      "\n",
      "3. If the input does not include style, lighting, atmosphere, you can make reasonable associations.\n",
      "\n",
      "4. Output ALL must be in English.\n",
      "\n",
      "Given Input:\n",
      "input: \"shrek dancing, wide angle shot, directed by ridley scott\"<|eos|>\n",
      "\n",
      "Request:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"<|start_header_id|>system<|end_header_id|>\\n\\nDescribe the video by detailing the following aspects: 1. The main content and theme of the video.2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.4. background environment, light, style and atmosphere.5. camera angles, movements, and transitions used in the video:<|eos|>\\n<|start_header_id|>user<|end_header_id|>\\n\\n<|eos|>\\nMaster mode - Video Recaption Task:\\n\\nYou are a large language model specialized in rewriting video descriptions. Your task is to modify the input description.\\n\\n0. Preserve ALL information, including style words and technical terms.\\n\\n1. If the input is in Chinese, translate the entire description to English. \\n\\n2. If the input is just one or two words describing an object or person, provide a brief, simple description focusing on basic visual characteristics. Limit the description to 1-2 short sentences.\\n\\n3. If the input does not include style, lighting, atmosphere, you can make reasonable associations.\\n\\n4. Output ALL must be in English.\\n\\nGiven Input:\\ninput: \\\"shrek dancing, wide angle shot, directed by ridley scott\\\"<|eos|>\"\n",
      "    }\n",
      "  ],\n",
      "  \"max_tokens\": 256,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_p\": 0.95,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"repetition_context_size\": 20,\n",
      "  \"stream\": true\n",
      "}\n",
      "<|startoftext|>Shrek dances, wide angle shot. Directed by Ridley Scott. Realistic, Natural lighting, Casual<|eos|><|eos|>\n",
      "Shrek dances energetically in a wide shot. Directed by Ridley Scott. Realistic style, natural lighting, creates a relaxed atmosphere. The camera movement is Static.<|eos|>Shrek dances energetically in a wide shot. Directed by Ridley Scott, the style is realistic with natural lighting creating a relaxed atmosphere. The camera movement is Static.<|eos|>Shrek dances energetically in a wide shot. Directed by Ridley Scott, the style is realistic with natural lighting creating a relaxed atmosphere. The camera movement is Static.<|eos|>Shrek dances energetically in a wide shot. Directed by Ridley Scott, the style is realistic with natural lighting creating a relaxed atmosphere. The camera movement is Static.<|eos|>Shrek dances energetically in a wide shot, directed by Ridley Scott. Realistic style, natural lighting creates a relaxed atmosphere. The camera movement is Static.<|eos|>Shrek dances energetically in a wide shot, directed by Ridley Scott. Realistic style, natural lighting creates a relaxed atmosphere. The camera movement is Static.<|eos|>Shrek dances energet"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 21\u001b[0m\n\u001b[1;32m      2\u001b[0m custom_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROMPT_TEMPLATE_ENCODE_VIDEO\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mMaster mode - Video Recaption Task:\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mGiven Input:\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124minput: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshrek dancing, wide angle shot, directed by ridley scott\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eos|>\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUsing custom prompt:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mrun_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 75\u001b[0m, in \u001b[0;36mrun_generation\u001b[0;34m(prompt, config, stream)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run generation with current settings\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m---> 75\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# New line at end\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 48\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt, config, stream)\u001b[0m\n\u001b[1;32m     45\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m---> 48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/requests/models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example 2: Custom raw prompt with special tokens\n",
    "custom_prompt = f\"\"\"{PROMPT_TEMPLATE_ENCODE_VIDEO}\n",
    "Master mode - Video Recaption Task:\n",
    "\n",
    "You are a large language model specialized in rewriting video descriptions. Your task is to modify the input description.\n",
    "\n",
    "0. Preserve ALL information, including style words and technical terms.\n",
    "\n",
    "1. If the input is in Chinese, translate the entire description to English. \n",
    "\n",
    "2. If the input is just one or two words describing an object or person, provide a brief, simple description focusing on basic visual characteristics. Limit the description to 1-2 short sentences.\n",
    "\n",
    "3. If the input does not include style, lighting, atmosphere, you can make reasonable associations.\n",
    "\n",
    "4. Output ALL must be in English.\n",
    "\n",
    "Given Input:\n",
    "input: \"shrek dancing, wide angle shot, directed by ridley scott\"<|eos|>\"\"\"\n",
    "\n",
    "print(\"\\nUsing custom prompt:\")\n",
    "run_generation(custom_prompt, master_config, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Custom raw prompt with special tokens\n",
    "custom_prompt = f\"\"\"<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
    "{PROMPT_TEMPLATE_ENCODE_VIDEO}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Describe a scene: shrek dancing\n",
    "<|eot_id|>\"\"\"\n",
    "\n",
    "print(\"\\nUsing custom prompt:\")\n",
    "run_generation(custom_prompt, master_config, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use master prompt with normal config\n",
    "prompt = get_rewrite_prompt(\"beach sunset\", mode=\"Master\")\n",
    "run_generation(prompt, normal_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_tokens = f\"<|startoftext|>{get_rewrite_prompt('mountain view', mode='Master')}<|eos|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"\"\"<|startoftext|><|start_header_id|>system<|end_header_id|>\n",
    "Your custom system prompt here\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Your custom user prompt here\n",
    "<|eot_id|>\"\"\"\n",
    "\n",
    "run_generation(custom_prompt, normal_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal mode\n",
    "prompt = get_rewrite_prompt(\"sunset beach\", mode=\"Normal\")\n",
    "run_generation(prompt, normal_config)\n",
    "\n",
    "# Master mode\n",
    "prompt = get_rewrite_prompt(\"city lights\", mode=\"Master\")\n",
    "run_generation(prompt, master_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = GenerationConfig(\n",
    "    temperature=0.5,\n",
    "    top_p=0.8,\n",
    "    debug=True\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
